wandb:
  run_name: llm-jp/llm-jp-13b-instruct-full-dolly-ichikara_004_001_single-oasst-oasst2-v2.0
api: vllm
num_gpus: 2
batch_size: 256
model:
  use_wandb_artifacts: false
  pretrained_model_name_or_path: llm-jp/llm-jp-13b-instruct-full-dolly-ichikara_004_001_single-oasst-oasst2-v2.0 #if you use openai api, put the name of model
  bfcl_model_name: "" # check the model name in "llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/SUPPORTED_MODELS.md"
  chat_template: llm-jp/llm-jp-13b-instruct-full-dolly-ichikara_004_001_single-oasst-oasst2-v2.0
  size_category: 10Bâ‰¤ <30B
  size: 13681710080
  release_date: 4/30/2024
