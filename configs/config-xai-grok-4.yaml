wandb:
  run_name: grok-4
api: "openai-compatible"
base_url: "https://openrouter.ai/api/v1"
batch_size: 32
model:
  pretrained_model_name_or_path: x-ai/grok-4 #if you use openai api, put the name of model
  bfcl_model_id: OpenRouter-FC  # find id from "llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/SUPPORTED_MODELS.md"
  base_model: unknown
  size_category: api
  size: null
  release_date: "7/9/2025"

generator:
  max_tokens: 128000
  extra_body:
    reasoning:
      max_tokens: 100000

jaster:
  override_max_tokens: 128000

jbbq:
  generator_config:
    max_tokens: 128000

toxicity:
  generator_config:
    max_tokens: 128000

jtruthfulqa:
  generator_config:
    max_tokens: 128000

swebench:
  max_tokens: 128000

mtbench:
  max_new_token: 128000

bfcl:
  generator_config:
    max_tokens: 128000

hallulens:
  generator_config:
    max_tokens: 128000

hle:
  max_completion_tokens: 128000

arc_agi:
  max_output_tokens: 128000

m_ifeval:
  generator_config:
    max_tokens: 128000
