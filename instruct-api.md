

# Task: BFCLã«ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ 
##ã€€è¿½åŠ ã—ãŸã„ãƒ¢ãƒ‡ãƒ«  â˜…(ã“ã“ã‚’å¤‰ãˆã‚‹)
- gpt-4.1-mini-2025-04-14
- o3-2025-04-16
- o4-mini-2025-04-16

## å¤‰æ›´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
### model specific â˜…(ã“ã“ã‚’å¤‰ãˆã‚‹)
- /home/olachinkeigpu/Project/llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/model_handler/api_inference/claude.py

### å…±é€š
- bfcl/model_handler/base_handler.py
- bfcl/constants/model_config.py
- /home/olachinkeigpu/Project/llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/SUPPORTED_MODELS.md # Nejumi Leaderboardã§è¿½åŠ ã—ãŸã¨ã„ã†ã“ã¨ã‚’ã‚ã‹ã‚Šã‚„ã™ãå…¥ã‚Œã‚‹

## è£œè¶³



## -------------------------------------------------------------------
## é€²ã‚æ–¹ï¼ˆReferenceï¼‰
- gitã§å¤‰æ›´ã‚’ç®¡ç†ã—ãªãŒã‚‰é€²ã‚ã€ã„ã¤ã§ã‚‚æˆ»ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦

#-----------ãƒ¢ãƒ‡ãƒ«å…±æœ‰------------
# è¿½åŠ ã®ãŸã‚ã®ç´°ã‹ã„instructionã¯ä¸‹è¨˜
### æ–°ã—ããƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•
- å…¬å¼ã®[Contributing Guide](./CONTRIBUTING.md)ã‚’ã”ç¢ºèªãã ã•ã„ã€‚ä»¥ä¸‹ã€æ—¥æœ¬èªã§ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ & Nejumi Leaderboardã«ç‰¹åŒ–ã—ãŸå¯¾å¿œã«ã¤ã„ã¦è§£èª¬ã‚’ã—ã¾ã™ã€‚

#### OSSãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
1. `bfcl/model_handler/local_inference/base_oss_handler.py`ã‚’ç¢ºèªã—ã¤ã¤ã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„handler classã‚’llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/model_handler/local_inferenceã«ä½œæˆã—ã¦ãã ã•ã„ã€‚
  - handlerã®ä½œæˆã«ã¤ã„ã¦ã¯ã€ã“ã¡ã‚‰ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚
2. ãã®å¾Œ`bfcl/constants/model_config.py`ã«ã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã™ã€‚
3. modelã”ã¨ã®configå†…ã®bfcl_model_nameã«`bfcl/constants/model_config.py`ã«è¿½åŠ ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„

#### APIã®å ´åˆ
1. `bfcl/model_handler/base_handler.py`ã‚’ç¢ºèªã—ã¤ã¤ã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„handler classã‚’llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/model_handler/api_inferenceã«ä½œæˆã—ã¦ä¸‹ã•ã„ã€‚
2. ãã®å¾Œ`bfcl/constants/model_config.py`ã«ã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’è¿½åŠ ã—ã¾ã™ã€‚
3. modelã”ã¨ã®configå†…ã®bfcl_model_nameã«`bfcl/constants/model_config.py`ã«è¿½åŠ ã—ãŸãƒ¢ãƒ‡ãƒ«åã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„

## ä»•çµ„ã¿ç†è§£ã®ãŸã‚ã®è§£èª¬
### è³ªå•1: bfcl/model_handler/base_handler.py ã¯ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ï¼Ÿ
**BaseHandlerã‚¯ãƒ©ã‚¹**ã¯ã€**BFCLï¼ˆBerkeley Function-calling Leaderboardï¼‰ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã®åŸºç›¤ã¨ãªã‚‹æŠ½è±¡ã‚¯ãƒ©ã‚¹**ã§ã™ã€‚

#### ğŸ¯ ä¸»è¦ãªå½¹å‰²ã¨æ©Ÿèƒ½

**1. ãƒ¢ãƒ‡ãƒ«æ¨è«–ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**
- ç•°ãªã‚‹APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOpenAIã€Claudeã€Geminiãªã©ï¼‰ã«å¯¾ã—ã¦å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›
- `inference()`ãƒ¡ã‚½ãƒƒãƒ‰ãŒæ¨è«–ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½
- Function Callingï¼ˆFCï¼‰ãƒ¢ãƒ¼ãƒ‰ã¨Promptingãƒ¢ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ

**2. ã‚·ãƒ³ã‚°ãƒ«ã‚¿ãƒ¼ãƒ³ã¨ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®å¯¾è©±å‡¦ç†**
- `inference_single_turn_FC/prompting()`: å˜ç™ºã®è³ªå•å¿œç­”å‡¦ç†
- `inference_multi_turn_FC/prompting()`: è¤‡æ•°å›ã®å¯¾è©±ã‚’è¡Œã†å‡¦ç†
- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§ã¯é–¢æ•°ã®å®Ÿè¡Œçµæœã‚’æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã«å¼•ãç¶™ãã€é€£ç¶šçš„ãªå¯¾è©±ãŒå¯èƒ½

**3. é–¢æ•°å‘¼ã³å‡ºã—ï¼ˆFunction Callingï¼‰ã®å®Ÿè¡Œç®¡ç†**
- ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰é–¢æ•°å®šç¾©ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒé©åˆ‡ãªé–¢æ•°ã‚’å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ç®¡ç†
- é–¢æ•°ã®å®Ÿè¡Œçµæœã‚’å–å¾—ã—ã€æ¬¡ã®ã‚¯ã‚¨ãƒªã«åæ˜ 
- `MAXIMUM_STEP_LIMIT`ã«ã‚ˆã‚‹ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢æ©Ÿèƒ½

**4. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®è¨ˆæ¸¬**
- å…¥åŠ›ãƒ»å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ­£ç¢ºãªè¨ˆæ¸¬
- APIå‘¼ã³å‡ºã—ã®å¿œç­”æ™‚é–“æ¸¬å®š
- è©•ä¾¡æŒ‡æ¨™ã¨ã—ã¦é‡è¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®åé›†

**5. çŠ¶æ…‹ç®¡ç†ã¨ãƒ­ã‚°è¨˜éŒ²**
- ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çŠ¶æ…‹å¤‰åŒ–ã‚’è¿½è·¡
- è©³ç´°ãªæ¨è«–ãƒ­ã‚°ã®è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
- å®Ÿè¡Œçµæœã®JSONå½¢å¼ã§ã®æ°¸ç¶šåŒ–

**6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
- ãƒ¢ãƒ‡ãƒ«å¿œç­”ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®é©åˆ‡ãªå‡¦ç†
- ã‚¹ãƒ†ãƒƒãƒ—æ•°ä¸Šé™ã«ã‚ˆã‚‹å¼·åˆ¶çµ‚äº†æ©Ÿèƒ½
- å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®æ•æ‰ã¨ãƒ­ã‚°è¨˜éŒ²

#### ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
BaseHandlerã‚¯ãƒ©ã‚¹ã¯**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³**ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦å®šç¾©ã•ã‚Œã€å„APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã®å…·ä½“çš„ãªå®Ÿè£…ãŒå¿…è¦ã§ã™ï¼š

**Function Callingãƒ¢ãƒ¼ãƒ‰ç”¨:**
- `_query_FC()`: APIã¸ã®å®Ÿéš›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
- `_pre_query_processing_FC()`: ã‚¯ã‚¨ãƒªå‰ã®å‰å‡¦ç†
- `_compile_tools()`: é–¢æ•°å®šç¾©ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
- `_parse_query_response_FC()`: APIå¿œç­”ã®è§£æ
- `add_first_turn_message_FC()`: åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
- `_add_assistant_message_FC()`: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã®è¿½åŠ 
- `_add_execution_results_FC()`: å®Ÿè¡Œçµæœã®è¿½åŠ 

**Promptingãƒ¢ãƒ¼ãƒ‰ç”¨:**
- `_query_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
- `_pre_query_processing_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰å‡¦ç†
- `_parse_query_response_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¿œç­”ã®è§£æ
- å¯¾å¿œã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

#### ğŸ’¡ FCãƒ¢ãƒ¼ãƒ‰ vs Promptingãƒ¢ãƒ¼ãƒ‰ã®é•ã„

| é …ç›® | FCãƒ¢ãƒ¼ãƒ‰ | Promptingãƒ¢ãƒ¼ãƒ‰ |
|------|----------|----------------|
| **å‡ºåŠ›å½¢å¼** | æ§‹é€ åŒ–ã•ã‚ŒãŸJSON | è‡ªç„¶è¨€èª+é–¢æ•°å‘¼ã³å‡ºã— |
| **ç²¾åº¦** | é«˜ã„ï¼ˆæ§‹é€ ãŒä¿è¨¼ï¼‰ | ä¸­ç¨‹åº¦ï¼ˆè§£æãŒå¿…è¦ï¼‰ |
| **å¯¾å¿œãƒ¢ãƒ‡ãƒ«** | OpenAIã€Claudeç­‰ã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ« | ã‚ˆã‚Šå¹…åºƒã„ãƒ¢ãƒ‡ãƒ« |
| **å®Ÿè£…ã®è¤‡é›‘ã•** | ã‚·ãƒ³ãƒ—ãƒ« | è¤‡é›‘ï¼ˆãƒ†ã‚­ã‚¹ãƒˆè§£æãŒå¿…è¦ï¼‰ |

**FCãƒ¢ãƒ¼ãƒ‰ã®ä¾‹:**
```python
# ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆæ§‹é€ åŒ–ï¼‰
{"tool_calls": [{"function": {"name": "get_weather", "arguments": "{\"location\": \"æ±äº¬\"}"}}]}
```

**Promptingãƒ¢ãƒ¼ãƒ‰ã®ä¾‹:**
```python
# ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆè‡ªç„¶è¨€èªï¼‰
"[get_weather(location='æ±äº¬')]"
# â†“ ASTè§£æãŒå¿…è¦
[{'get_weather': {'location': 'æ±äº¬'}}]
```

#### ğŸ”§ ASTè§£æï¼ˆAbstract Syntax Treeè§£æï¼‰ã®ä»•çµ„ã¿

Promptingãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã—ãŸè‡ªç„¶è¨€èªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰Pythonã®é–¢æ•°å‘¼ã³å‡ºã—ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ASTè§£æã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

**1. ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†**
```python
# "[get_weather(location='æ±äº¬')]" â†’ "get_weather(location='æ±äº¬')"
cleaned_input = input_str.strip("[]'")
```

**2. Pythonã®ASTãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§æ§‹æ–‡è§£æ**
```python
parsed = ast.parse(cleaned_input, mode="eval")
```

**3. é–¢æ•°å‘¼ã³å‡ºã—ã¨å¼•æ•°ã®æŠ½å‡º**
```python
# æœ€çµ‚å‡ºåŠ›: [{'get_weather': {'location': 'æ±äº¬'}}]
```

#### âš¡ é–¢æ•°å®Ÿè¡Œã®ä»•çµ„ã¿

**é‡è¦**: APIãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯é–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚å®Ÿéš›ã®é–¢æ•°å®Ÿè¡Œã¯BFCLã‚·ã‚¹ãƒ†ãƒ å´ã§è¡Œã‚ã‚Œã¾ã™ã€‚

**APIãƒ¢ãƒ‡ãƒ«ã®å½¹å‰²**: 
- é–¢æ•°å‘¼ã³å‡ºã—ã®æŒ‡ç¤ºã‚’ç”Ÿæˆã™ã‚‹ã®ã¿
- å®Ÿéš›ã®å‡¦ç†ã¯è¡Œã‚ãªã„

**BFCLã‚·ã‚¹ãƒ†ãƒ ã®å½¹å‰²**: ã€Œå®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ã€
- å®Ÿéš›ã®Pythonã‚¯ãƒ©ã‚¹ã‚’å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰
- é–¢æ•°ã‚’å®Ÿéš›ã«å®Ÿè¡Œï¼ˆ`eval()`ä½¿ç”¨ï¼‰
- å®Ÿè¡Œçµæœã‚’ãƒ¢ãƒ‡ãƒ«ã«è¿”å´

```python
# å®Ÿéš›ã®é–¢æ•°å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹
def execute_multi_turn_func_call():
    # 1. å®Ÿéš›ã®Pythonã‚¯ãƒ©ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰
    class_instance = TradingBot()
    
    # 2. é–¢æ•°å®Ÿè¡Œ
    result = eval("class_instance.place_order(symbol='AAPL', amount=100)")
    
    # 3. çµæœã‚’ãƒ¢ãƒ‡ãƒ«ã«è¿”å´
    return result
```

### è³ªå•2: bfcl/model_handler/api_inferenceã§å„ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ï¼Ÿ

api_inferenceãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯**20å€‹ä»¥ä¸Šã®APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼**ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãã‚Œãã‚ŒãŒBaseHandlerã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã¦ç‰¹å®šã®APIä»•æ§˜ã«å¯¾å¿œã—ãŸå®Ÿè£…ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

#### ğŸ”§ å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®å…±é€šå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

**å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ä»¥ä¸‹ã‚’å¿…ãšå®Ÿè£…:**
1. **APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–**: å„ã‚µãƒ¼ãƒ“ã‚¹å›ºæœ‰ã®èªè¨¼ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
2. **ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š**: `ModelStyle`enumå€¤ã®è¨­å®š
3. **ã‚¯ã‚¨ãƒªãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…**: `_query_FC()`ã¨`_query_prompting()`
4. **å¿œç­”è§£æã®å®Ÿè£…**: APIå›ºæœ‰ã®å¿œç­”å½¢å¼ã‹ã‚‰ã®æ¨™æº–å½¢å¼ã¸ã®å¤‰æ›
5. **ãƒ‡ã‚³ãƒ¼ãƒ‰æ©Ÿèƒ½**: `decode_ast()`ã¨`decode_execute()`ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
6. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: APIå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ç­‰ï¼‰ã¸ã®å¯¾å¿œ

#### ğŸ¢ ä¸»è¦APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ç‰¹å¾´çš„ãªé•ã„

**1. openai.py - OpenAIHandler**
```python
class OpenAIHandler(BaseHandler):
    def __init__(self, model_name, temperature):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    def _query_FC(self, inference_data: dict):
        # ã‚·ãƒ³ãƒ—ãƒ«ã§æ¨™æº–çš„
        return self.generate_with_backoff(
            messages=messages,
            model="gpt-4",
            tools=tools,
            temperature=0.7  # ãŸã ã—o1ãƒ¢ãƒ‡ãƒ«ã§ã¯ä½¿ç”¨ä¸å¯
        )
```
**ç‰¹å¾´:**
- âœ… æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…
- âœ… æ¨™æº–çš„ãªFunction Callingå½¢å¼
- âš ï¸ o1/o3-miniãƒ¢ãƒ‡ãƒ«ã¯æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿éå¯¾å¿œ

**2. claude.py - ClaudeHandler**
```python
class ClaudeHandler(BaseHandler):
    def _query_FC(self, inference_data: dict):
        # ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½ä»˜ã
        if inference_data["caching_enabled"]:
            # ç›´è¿‘2ã¤ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            for message in reversed(messages):
                if message["role"] == "user":
                    message["content"][0]["cache_control"] = {"type": "ephemeral"}
        
        return self.generate_with_backoff(
            model="claude-3-sonnet",
            messages=messages_with_cache_control,
            tools=tools,
            max_tokens=8192  # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹
        )
```
**ç‰¹å¾´:**
- ğŸš€ **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½**: ç›´è¿‘2ã¤ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- ğŸ“ **å¯å¤‰ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™**: Opusã¯4096ã€Sonnetã¯8192
- ğŸ”„ **ç‰¹æ®Šãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†**: cache_control ãƒ•ãƒ©ã‚°ã‚’å‹•çš„ã«ç®¡ç†

**3. gemini.py - GeminiHandler**
```python
class GeminiHandler(BaseHandler):
    def _query_FC(self, inference_data: dict):
        # Google Cloudç‰¹æœ‰ã®è¤‡é›‘ãªå¤‰æ›
        func_declarations = []
        for function in inference_data["tools"]:
            func_declarations.append(
                FunctionDeclaration(
                    name=function["name"],
                    description=function["description"],
                    parameters=function["parameters"],
                )
            )
        
        tools = [Tool(function_declarations=func_declarations)]
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå†ä½œæˆ
        if "system_prompt" in inference_data:
            client = GenerativeModel(
                self.model_name,
                system_instruction=inference_data["system_prompt"]
            )
```
**ç‰¹å¾´:**
- ğŸ”§ **è¤‡é›‘ãªå¤‰æ›å‡¦ç†**: é–¢æ•°ã‚’FunctionDeclarationâ†’Toolã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
- ğŸ—ï¸ **å‹•çš„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆ**: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã¯ãƒ¢ãƒ‡ãƒ«å†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
- ğŸŒ **Google Cloudçµ±åˆ**: Vertex AIçµŒç”±ã§ã®ã‚¢ã‚¯ã‚»ã‚¹

**4. ãã®ä»–ã®å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼**
- **mistral.py**: Mistral AI APIå¯¾å¿œã€ç‹¬è‡ªã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å½¢å¼
- **cohere.py**: Cohere APIå¯¾å¿œã€ç‹¬è‡ªã®ãƒ„ãƒ¼ãƒ«å®šç¾©å½¢å¼
- **yi.py**: Yi AI APIå¯¾å¿œ
- **deepseek.py**: DeepSeek APIå¯¾å¿œ
- **databricks.py**: Databricks APIå¯¾å¿œ
- **nova.py**: Nova APIå¯¾å¿œ
- **nexus.py**: Nexus APIå¯¾å¿œï¼ˆã‚»ãƒŸã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚Šå½¢å¼ï¼‰
- **gorilla.py**: Gorilla APIå¯¾å¿œ
- **fireworks.py**: Fireworks AI APIå¯¾å¿œ
- **nvidia.py**: NVIDIA APIå¯¾å¿œ
- **writer.py**: Writer APIå¯¾å¿œ
- **novita.py**: Novita APIå¯¾å¿œ
- **qwq.py**: QwQ APIå¯¾å¿œ
- **grok.py**: xAI Grok APIå¯¾å¿œ

#### ğŸ“Š å®Ÿè£…ã®è¤‡é›‘ã•æ¯”è¼ƒ

| API | å®Ÿè£…è¤‡é›‘åº¦ | ç‰¹æ®Šæ©Ÿèƒ½ | æ³¨æ„ç‚¹ |
|-----|-------------|----------|--------|
| **OpenAI** | â­â­ | o1ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ | æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ« |
| **Claude** | â­â­â­ | ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ãŒç‰¹æ®Š |
| **Gemini** | â­â­â­â­ | å‹•çš„ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ | Google Cloudè¨­å®šå¿…è¦ |
| **Cohere** | â­â­â­ | ç‹¬è‡ªãƒ„ãƒ¼ãƒ«å½¢å¼ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒå¤‰æ› |
| **ãã®ä»–** | â­â­ | åŸºæœ¬çš„ãªå®Ÿè£… | OpenAIäº’æ›ãŒå¤šã„ |

#### ğŸ¨ Promptingãƒ¢ãƒ¼ãƒ‰ã§ã®ç‰¹æ®Šå‡¦ç†ä¾‹

**Hermesï¼ˆXMLã‚¿ã‚°ãƒ™ãƒ¼ã‚¹ï¼‰**
```python
def decode_ast(self, result):
    lines = result.split("\n")
    func_call = []
    for line in lines:
        if "<tool_call>" == line:
            flag = True
        elif "</tool_call>" == line:
            flag = False
        elif flag:
            tool_result = json.loads(line)
            func_call.append({tool_result["name"]: tool_result["arguments"]})
    return func_call
```

**MiningHandlerï¼ˆç‰¹æ®Šãƒ‘ãƒ¼ã‚¹ï¼‰**
```python
def _parse_query_response_prompting(self, api_response):
    # <tool_calls>ã‚¿ã‚°å†…ã®JSONã‚’æŠ½å‡º
    match = re.search(r'<tool_calls>\n(.*?)\n</tool_calls>', content, re.DOTALL)
    if match:
        tool_calls = match.group(1).strip()
        tool_calls = json.loads(tool_calls.replace("'",'"'))
    return {"model_responses": tool_calls, ...}
```