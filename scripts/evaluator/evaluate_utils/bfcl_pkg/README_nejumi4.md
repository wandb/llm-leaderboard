
# Nejumi Leaderboardã§è¡Œã£ãŸBFCLã®å¤‰æ›´ã¨è£œè¶³

## Nejumi Leaderboardã®ãŸã‚ã«è¡Œã£ãŸå¤‰æ›´
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€BFCLã‚’Nejumi Leaderboardã«çµ±åˆã™ã‚‹ãŸã‚ã«è¡Œã£ãŸå…·ä½“çš„ãªå¤‰æ›´ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¾ã™ã€‚

- è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ—¥æœ¬èªåŒ–ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    - qwen/qwen3-235b-a22bã‚’ç”¨ã„ã¦ãƒ™ãƒ¼ã‚¹ç¿»è¨³ã€‚äººæ‰‹ã§ä¿®æ­£ã‚‚å®Ÿæ–½
    - llm-leaderboard/scripts/translation/bfcl_translation.pyã‚’åˆ©ç”¨
        - **ãƒ«ãƒ¼ãƒ«**: é–¢æ•°åã€ã‚³ãƒ¼ãƒ‰é–¢é€£å†…å®¹ã¯ç¿»è¨³å¯¾è±¡å¤–
    - llm-leaderboard/scripts/translation/bfcl_multi_turn_count.pyã‚’ç”¨ã„ã¦ã€Turnæ•°ã‚’è¨ˆç®—
    - llm-leaderboard/scripts/translation/sort_bfcl_file.pyã‚’ç”¨ã„ã¦ä¸¦ã³æ›¿ãˆ
    - llm-leaderboard/scripts/data_uploader/upload_dataset.pyã‚’ç”¨ã„ã¦W&Bã«upload
    - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯WandBã®artifactsã«ä¿å­˜ [link](https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/artifacts/dataset/bfcl)
    - Nejumi Leaderboardã§ã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ã—ã¦å®Ÿè£…
        - åŸºæœ¬çš„ã«å„ã‚«ãƒ†ã‚´ãƒª30å•ã‚’åˆ©ç”¨ã€‚30å•ã«æº€ãŸãªã„å•é¡Œã¯å…¨å•
        - live_parallel_multiple, live_multiple: å•é¡Œæ–‡ã«è‹±èªä»¥å¤–ã®è³ªå•ãŒå«ã‚€ä»¥ä¸‹ã®å•é¡Œã‚’å‰Šé™¤
            - live_parallel_multiple
                - live_parallel_multiple_1-1-0
                - live_parallel_multiple_2-2-0
                - live_parallel_multiple_3-2-1
            - parallel_multiple
                - live_multiple_2-1-0
                - live_multiple_4-2-1
                - live_multiple_6-3-1
                - live_multiple_7-3-2
                - live_multiple_10-4-2
                - live_multiple_14-4-6
                - live_multiple_16-4-8
                - live_multiple_19-4-11
                - live_multiple_20-4-12
                - live_multiple_21-4-13
                - live_multiple_22-4-14
        - ä¸Šè¨˜artifactsã«ä¿å­˜ã™ã‚‹ã«ã‚ãŸã‚Šäººæ‰‹ã§ã®ç¿»è¨³ç¢ºèªã®å“è³ªæ‹…ä¿ã®ãŸã‚ã€ä»¥ä¸‹ã®å•é¡Œã¯50å•ã«çµã£ã¦ä¿å­˜
            - live_multiple, multiple, simple, parallel_multiple
        - possible answerã«æ—¥æœ¬èªã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            - live_multiple, live_parallel, multiple, simple, parallel_multiple
        - æŒ‡ç¤ºæ–‡ã®è¨€èªæŒ‡å®šã‚’ã™ã‚‹ã¹ãã¨åˆ¤æ–­ã—ãŸå•é¡Œã«ã€è‹±èªã§å›ç­”ã—ã¦ã¨ã„ã†æŒ‡ç¤ºã‚’è¿½åŠ 
            - live_parallel, parallel_multiple
- `scripts/run_eval.py`ã«BFCLè©•ä¾¡ã‚’çµ±åˆ
- BFCLä¾å­˜é–¢ä¿‚ã«ä¼´ã†uv.lockã®æ›´æ–°ã¨uvãƒ™ãƒ¼ã‚¹ã®ä¾å­˜é–¢ä¿‚ç®¡ç†ã¸ã®ç§»è¡Œ
- `scripts/evaluator/bfcl.py`ã®ä½œæˆ
  - WandBConfigSingletonã¨ã®çµ±åˆ
  - è¨­å®šã®å‹•çš„ãƒãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ + ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šï¼‰
  - ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™ï¼‰
  - WandB Artifactã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—
  - è©•ä¾¡çµæœã®WandBãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
- base_configã¸ã®è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¿½åŠ :
- bfclã‚’packageã¨ã—ã¦downloadã—ãªã„ã‚ˆã†ã«å¤‰æ›´ã€‚bfcl_pkgå†…ã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›
- llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/constants/eval_config.pyå†…ã®pathã‚’å¤‰æ›´
- llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/eval_checker/multi_turn_eval/func_source_codeå†…ã®long_context.pyã‚’å®Ÿè¡Œæ™‚ã«pathã®å•é¡Œã§åˆ©ç”¨ã§ããªã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã£ãŸã®ã§ã€è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã«long_context.pyå†…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
- W&Bã¸ã®çµæœè¡¨ç¤º
  - W&Bã®Tableã«è©³ç´°ãªçµæœã‚’æ®‹ã™ãŸã‚ã«ã€å‡ºåŠ›ã•ã‚Œã‚‹score fileã«ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒè¿½åŠ ã•ã‚Œã‚‹ã‚ˆã†ã«å¤‰æ›´(æˆåŠŸãƒ»å¤±æ•—ä¸¡æ–¹ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§è©³ç´°æƒ…å ±ã‚’åŒ…å«)
- ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®config fileã«BFCLã®model idã‚’è¿½åŠ 
- ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§: å•é¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨possible_answerãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸¡æ–¹ã§åŒã˜é †ç•ªãŒä¿ãŸã‚Œã‚‹(sortã‚’falseã«ã™ã‚‹ãªã©)
- ã‚¯ãƒ©ã‚¹åãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒã¸ã®å¤‰æ›´
    - å•é¡Œï¼štype()æ¯”è¼ƒãŒç•°ãªã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§å¤±æ•—(packageã®æ–¹æ³•ã‚’è¸è¥²ã—ãªã‹ã£ãŸã®ã§å•é¡Œã«ãªã£ãŸ)
    - ä¿®æ­£ï¼š__class__.__name__ã«ã‚ˆã‚‹æ¯”è¼ƒã«å¤‰æ›´
    - å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼šmulti_turn_checker.pyã¨å„APIã‚¯ãƒ©ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
- Leading Zerosã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£
    - å•é¡Œï¼šPython 3ã§ã®8é€²æ•°è§£é‡ˆã«ã‚ˆã‚‹TypeError
    - ä¿®æ­£ï¼šæ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹leading zerosã®10é€²æ•°å¤‰æ›
    - å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼šmulti_turn_utils.py
- llm-leadrboardã§èµ·å‹•ã•ã‚Œã‚‹vllmã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
    - llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/model_handler/local_inference/base_oss_handler.pyã®vllm_hostã¨portã‚’å¤‰æ›´
- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®chat templateã¸ã®å¯¾å¿œ
    - ã‚ªãƒªã‚¸ãƒŠãƒ«ã®BFCLã§ã¯ã€vllmèµ·å‹•æ™‚ã«chat templateã‚’åˆ©ç”¨ã›ãšã€æ¨è«–å®Ÿè¡Œæ™‚ã«ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®classã§templateã®å¯¾å¿œã‚’è¡Œãªã£ã¦ã„ãŸã€‚Nejumi leaderboardã§ã¯ã€vllmèµ·å‹•æ™‚ã«chat templateã‚’åˆ©ç”¨ã™ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®classå†…ã§ã®chat templateã‚’å‰Šé™¤ã—ã€llm-leaderboard/scripts/evaluator/evaluate_utils/bfcl_pkg/bfcl/model_handler/local_inference/base_oss_handler.pyå†…ã§OSSHandlerå†…ã§Chat Completionå½¢å¼ã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è¨­å®šé …ç›®ãŒå¤§å¹…ã«ç°¡ç´ åŒ–ã•ã‚Œã¾ã—ãŸã€‚
    - ä¸è¦ã«ãªã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
    - **`_format_prompt`**: Chat Completions APIãŒå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ä¸è¦ã€‚ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®äºŒé‡é©ç”¨å•é¡Œã‚‚è§£æ±ºã•ã‚Œã‚‹
    - ä¾ç„¶ã¨ã—ã¦å¿…è¦ãªãƒ¡ã‚½ãƒƒãƒ‰
    - **`decode_ast`/`decode_execute`**: å‡ºåŠ›ãƒ‘ãƒ¼ã‚¹ã¯æ¨¡å‹å›ºæœ‰ã®ãŸã‚å¿…è¦
    - **`_pre_query_processing_prompting`**: å‰å‡¦ç†ã¯æ¨¡å‹å›ºæœ‰ã®ãŸã‚å¿…è¦ã€‚è©³ç´°ã¯ä»¥ä¸‹ã§è§£èª¬ã—ã¾ã™ã€‚

## æ–°ã—ããƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•
- å…¬å¼ã®[Contributing Guide](./CONTRIBUTING.md)ã‚’ã”ç¢ºèªãã ã•ã„ã€‚ä»¥ä¸‹ã€æ—¥æœ¬èªã§ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ & Nejumi Leaderboardã«ç‰¹åŒ–ã—ãŸå¯¾å¿œã«ã¤ã„ã¦è§£èª¬ã‚’ã—ã¾ã™ã€‚


## æ§‹é€ è§£èª¬ï¼ˆã‚‚ã†å°‘ã—organizeã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
### å®Ÿè£…è©³ç´°
- bfcl.pyãŒå®Ÿè£…ã•ã‚Œã‚‹ã¨`_llm_response_generation.py`ã®ä¸­ã®`generation_main`ãŒå®Ÿè£…ã•ã‚Œã€ãã“ã‹ã‚‰`gerate_results`ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹
- `build_handler`ã§handlerãŒinstanceåŒ–ã•ã‚Œã‚‹
    - handlerã¯bfcl_model_idã«ç´ä»˜ãã€`bfcl/constants/model_config.py`ã§mappingã•ã‚Œã¦instanceåŒ–ã•ã‚Œã‚‹
    - base_handlerã®classãŒå…¨ã¦ã®ãƒ™ãƒ¼ã‚¹
    - ä¾‹: Qwenã®å ´åˆã€Qwen/XX-FCã¨ã„ã†åå‰ã‚’bfcl_model_idã§è¨­å®šã™ã‚‹ã¨ã€`bfcl/model_handler/local_inference/qwen_fc.py`ã®`QwenFCHandler`ãŒå‘¼ã°ã‚Œã‚‹
    - `QwenFCHandler`ã¯`OSSHandler`ã‚’ç¶™æ‰¿ã—ã€`OSSHandler`ã¯`BaseHandler`ã‚’ç¶™æ‰¿

### OSSã‚’å®Ÿè£…ã™ã‚‹å ´åˆ (vllmã§ã®å®Ÿè£…, qwen, deepseekã®ã‚ˆã†ã«ãƒ™ãƒ³ãƒ€ãƒ¼ã®APIã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯ã“ã¡ã‚‰ã§ã¯ãªã„)
- `OSSHandler`ã§ã¯ã€ä»¥ä¸‹ãŒå®Ÿè£…
    - llm = instance.llm
    - Function callingã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã€UnifiedOSSFCHandlerã‚’åˆ©ç”¨
    - Function callingã‚’åˆ©ç”¨ã—ãªã„å ´åˆã€UnifiedOSSFCHandlerã‚’åˆ©ç”¨(å®Œç’§ã¨ã¯è¨€ã‚ãªã„ãŒã€chat templateã‹ã‚‰ã§ãã‚‹ã ã‘å¯¾å¿œ)

### APIã‚’å®Ÿè£…ã™ã‚‹å ´åˆ (ãƒ™ãƒ³ãƒ€ãƒ¼ã®APIå®Ÿè£…)
- APIã‚’ä½¿ã£ã¦ã„ãå ´åˆã¯ã€`BaseHandler`ã‚’è¸è¥²ã—ãŸãƒ™ãƒ³ãƒ€ãƒ¼ã”ã¨ã®classãŒå­˜åœ¨

### ç–‘å•ã«æ€ã†ãƒã‚¤ãƒ³ãƒˆï¼ˆã‚‚ã†å°‘ã—organizeã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
#### bfcl/model_handler/base_handler.py ã¯ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ï¼Ÿ
BaseHandlerã‚¯ãƒ©ã‚¹ã¯ã€BFCLï¼ˆBerkeley Function-calling Leaderboardï¼‰ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã®åŸºç›¤ã¨ãªã‚‹æŠ½è±¡ã‚¯ãƒ©ã‚¹ã§ã™ã€‚

- ä¸»è¦ãªå½¹å‰²ã¨æ©Ÿèƒ½
    1. ãƒ¢ãƒ‡ãƒ«æ¨è«–ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    - ç•°ãªã‚‹APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOpenAIã€Claudeã€Geminiãªã©ï¼‰ã«å¯¾ã—ã¦å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›
    - `inference()`ãƒ¡ã‚½ãƒƒãƒ‰ãŒæ¨è«–ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½
    - Function Callingï¼ˆFCï¼‰ãƒ¢ãƒ¼ãƒ‰ã¨Promptingãƒ¢ãƒ¼ãƒ‰ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ

    2. ã‚·ãƒ³ã‚°ãƒ«ã‚¿ãƒ¼ãƒ³ã¨ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®å¯¾è©±å‡¦ç†
    - `inference_single_turn_FC/prompting()`: å˜ç™ºã®è³ªå•å¿œç­”å‡¦ç†
    - `inference_multi_turn_FC/prompting()`: è¤‡æ•°å›ã®å¯¾è©±ã‚’è¡Œã†å‡¦ç†
    - ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§ã¯é–¢æ•°ã®å®Ÿè¡Œçµæœã‚’æ¬¡ã®ã‚¿ãƒ¼ãƒ³ã«å¼•ãç¶™ãã€é€£ç¶šçš„ãªå¯¾è©±ãŒå¯èƒ½

    3. é–¢æ•°å‘¼ã³å‡ºã—ï¼ˆFunction Callingï¼‰ã®å®Ÿè¡Œç®¡ç†
    - ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰é–¢æ•°å®šç¾©ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒé©åˆ‡ãªé–¢æ•°ã‚’å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ç®¡ç†
    - é–¢æ•°ã®å®Ÿè¡Œçµæœã‚’å–å¾—ã—ã€æ¬¡ã®ã‚¯ã‚¨ãƒªã«åæ˜ 
    - `MAXIMUM_STEP_LIMIT`ã«ã‚ˆã‚‹ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢æ©Ÿèƒ½

    4. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®è¨ˆæ¸¬
    - å…¥åŠ›ãƒ»å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ­£ç¢ºãªè¨ˆæ¸¬
    - APIå‘¼ã³å‡ºã—ã®å¿œç­”æ™‚é–“æ¸¬å®š
    - è©•ä¾¡æŒ‡æ¨™ã¨ã—ã¦é‡è¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®åé›†

    5. çŠ¶æ…‹ç®¡ç†ã¨ãƒ­ã‚°è¨˜éŒ²
    - ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®çŠ¶æ…‹å¤‰åŒ–ã‚’è¿½è·¡
    - è©³ç´°ãªæ¨è«–ãƒ­ã‚°ã®è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    - å®Ÿè¡Œçµæœã®JSONå½¢å¼ã§ã®æ°¸ç¶šåŒ–

    6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - ãƒ¢ãƒ‡ãƒ«å¿œç­”ã®ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®é©åˆ‡ãªå‡¦ç†
    - ã‚¹ãƒ†ãƒƒãƒ—æ•°ä¸Šé™ã«ã‚ˆã‚‹å¼·åˆ¶çµ‚äº†æ©Ÿèƒ½
    - å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼ã®æ•æ‰ã¨ãƒ­ã‚°è¨˜éŒ²

- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
    - BaseHandlerã‚¯ãƒ©ã‚¹ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦å®šç¾©ã•ã‚Œã€å„APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã®å…·ä½“çš„ãªå®Ÿè£…ãŒå¿…è¦ã§ã™ï¼š
    - Function Callingãƒ¢ãƒ¼ãƒ‰ç”¨:
        - `_query_FC()`: APIã¸ã®å®Ÿéš›ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        - `_pre_query_processing_FC()`: ã‚¯ã‚¨ãƒªå‰ã®å‰å‡¦ç†
        - `_compile_tools()`: é–¢æ•°å®šç¾©ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        - `_parse_query_response_FC()`: APIå¿œç­”ã®è§£æ
        - `add_first_turn_message_FC()`: åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
        - `_add_assistant_message_FC()`: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã®è¿½åŠ 
        - `_add_execution_results_FC()`: å®Ÿè¡Œçµæœã®è¿½åŠ 
    - Promptingãƒ¢ãƒ¼ãƒ‰ç”¨:
        - `_query_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        - `_pre_query_processing_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰å‡¦ç†
        - `_parse_query_response_prompting()`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¿œç­”ã®è§£æ
        - å¯¾å¿œã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

    -ğŸ’¡ FCãƒ¢ãƒ¼ãƒ‰ vs Promptingãƒ¢ãƒ¼ãƒ‰ã®é•ã„

    | é …ç›® | FCãƒ¢ãƒ¼ãƒ‰ | Promptingãƒ¢ãƒ¼ãƒ‰ |
    |------|----------|----------------|
    | **å‡ºåŠ›å½¢å¼** | æ§‹é€ åŒ–ã•ã‚ŒãŸJSON | è‡ªç„¶è¨€èª+é–¢æ•°å‘¼ã³å‡ºã— |
    | **ç²¾åº¦** | é«˜ã„ï¼ˆæ§‹é€ ãŒä¿è¨¼ï¼‰ | ä¸­ç¨‹åº¦ï¼ˆè§£æãŒå¿…è¦ï¼‰ |
    | **å¯¾å¿œãƒ¢ãƒ‡ãƒ«** | OpenAIã€Claudeç­‰ã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ« | ã‚ˆã‚Šå¹…åºƒã„ãƒ¢ãƒ‡ãƒ« |
    | **å®Ÿè£…ã®è¤‡é›‘ã•** | ã‚·ãƒ³ãƒ—ãƒ« | è¤‡é›‘ï¼ˆãƒ†ã‚­ã‚¹ãƒˆè§£æãŒå¿…è¦ï¼‰ |

    FCãƒ¢ãƒ¼ãƒ‰ã®ä¾‹:
    ```python
    # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆæ§‹é€ åŒ–ï¼‰
    {"tool_calls": [{"function": {"name": "get_weather", "arguments": "{\"location\": \"æ±äº¬\"}"}}]}
    ```

    Promptingãƒ¢ãƒ¼ãƒ‰ã®ä¾‹:
    ```python
    # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼ˆè‡ªç„¶è¨€èªï¼‰
    "[get_weather(location='æ±äº¬')]"
    # â†“ ASTè§£æãŒå¿…è¦
    [{'get_weather': {'location': 'æ±äº¬'}}]
    ```

- ASTè§£æï¼ˆAbstract Syntax Treeè§£æï¼‰ã®ä»•çµ„ã¿
    - Promptingãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã—ãŸè‡ªç„¶è¨€èªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰Pythonã®é–¢æ•°å‘¼ã³å‡ºã—ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ASTè§£æã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

    1. ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
    ```python
    # "[get_weather(location='æ±äº¬')]" â†’ "get_weather(location='æ±äº¬')"
    cleaned_input = input_str.strip("[]'")
    ```

    2. Pythonã®ASTãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§æ§‹æ–‡è§£æ
    ```python
    parsed = ast.parse(cleaned_input, mode="eval")
    ```

    3. é–¢æ•°å‘¼ã³å‡ºã—ã¨å¼•æ•°ã®æŠ½å‡º
    ```python
    # æœ€çµ‚å‡ºåŠ›: [{'get_weather': {'location': 'æ±äº¬'}}]
    ```

- é–¢æ•°å®Ÿè¡Œã®ä»•çµ„ã¿
    - **é‡è¦**: APIãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯é–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚å®Ÿéš›ã®é–¢æ•°å®Ÿè¡Œã¯BFCLã‚·ã‚¹ãƒ†ãƒ å´ã§è¡Œã‚ã‚Œã¾ã™ã€‚
    ```python
    # å®Ÿéš›ã®é–¢æ•°å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹
    def execute_multi_turn_func_call():
        # 1. å®Ÿéš›ã®Pythonã‚¯ãƒ©ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰
        class_instance = TradingBot()
        
        # 2. é–¢æ•°å®Ÿè¡Œ
        result = eval("class_instance.place_order(symbol='AAPL', amount=100)")
        
        # 3. çµæœã‚’ãƒ¢ãƒ‡ãƒ«ã«è¿”å´
        return result
    ```

#### 2: bfcl/model_handler/api_inferenceã§å„ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ï¼Ÿ

- api_inferenceãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯**20å€‹ä»¥ä¸Šã®APIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼**ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãã‚Œãã‚ŒãŒBaseHandlerã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã¦ç‰¹å®šã®APIä»•æ§˜ã«å¯¾å¿œã—ãŸå®Ÿè£…ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

    **å„ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã¯ä»¥ä¸‹ã‚’å®Ÿè£…:**
    1. **APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–**: å„ã‚µãƒ¼ãƒ“ã‚¹å›ºæœ‰ã®èªè¨¼ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
    2. **ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š**: `ModelStyle`enumå€¤ã®è¨­å®š
    3. **ã‚¯ã‚¨ãƒªãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…**: `_query_FC()`ã¨`_query_prompting()`
    4. **å¿œç­”è§£æã®å®Ÿè£…**: APIå›ºæœ‰ã®å¿œç­”å½¢å¼ã‹ã‚‰ã®æ¨™æº–å½¢å¼ã¸ã®å¤‰æ›
    5. **ãƒ‡ã‚³ãƒ¼ãƒ‰æ©Ÿèƒ½**: `decode_ast()`ã¨`decode_execute()`ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    6. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: APIå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ç­‰ï¼‰ã¸ã®å¯¾å¿œ


### 3: bfcl/model_handler/local_inference/base_oss_handler.pyãŒã‚„ã£ã¦ã„ã‚‹ã“ã¨ã‚’æ•™ãˆã¦
**base_oss_handler.py**ã¯ã€**OSSï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼‰ãƒ¢ãƒ‡ãƒ«ã€ã¤ã¾ã‚Šãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ç”¨ã®åŸºç›¤ã‚¯ãƒ©ã‚¹**ã§ã™ã€‚BaseHandlerã‚’ç¶™æ‰¿ã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ç‰¹æœ‰ã®å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

- ğŸ—ï¸ ä¸»è¦ãªå½¹å‰²ã¨æ©Ÿèƒ½
    1. Chat Completions API ã¸ã®å¯¾å¿œï¼ˆé‡è¦ãªå¤‰æ›´ç‚¹ï¼‰

        å¾“æ¥ã®BFCL: å„ãƒ¢ãƒ‡ãƒ«ã§å€‹åˆ¥ã«chat templateã‚’å‡¦ç†
        ```python
        # æ—§å®Ÿè£…ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
        def _format_prompt(self, messages, function):
            # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«å€‹åˆ¥ã®chat templateå‡¦ç†
            formatted_prompt = apply_chat_template(messages)
            return formatted_prompt
        ```

        ç¾åœ¨ã®Nejumi leaderboard: vLLMã‚µãƒ¼ãƒãƒ¼å´ã§chat templateã‚’çµ±ä¸€å‡¦ç†
        ```python
        # æ–°å®Ÿè£…
        def _query_prompting(self, inference_data: dict):
            # Chat Completions APIã§ã¯vLLMã‚µãƒ¼ãƒãƒ¼å´ã§chat templateãŒé©ç”¨ã•ã‚Œã‚‹ãŸã‚ã€
            # _format_promptã¯ä½¿ç”¨ã›ãšã€ç›´æ¥messagesã‚’é€ä¿¡ã™ã‚‹
            api_response = self.client.chat.completions.create(
                model=self.model_path_or_id,
                temperature=self.temperature,
                messages=message,  # ç›´æ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
                max_tokens=leftover_tokens_count,
            )
        ```

    2. vLLMã‚µãƒ¼ãƒãƒ¼ã¨ã®é€šä¿¡ç®¡ç†
    ```python
    class OSSHandler(BaseHandler):
        def __init__(self, model_name, temperature, dtype="bfloat16"):
            # vLLMã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šè¨­å®š
            self.vllm_host = os.getenv("VLLM_ENDPOINT", "localhost")
            self.vllm_port = os.getenv("VLLM_PORT", VLLM_PORT)
            self.base_url = f"http://{self.vllm_host}:{self.vllm_port}/v1"
            self.client = OpenAI(base_url=self.base_url, api_key="EMPTY")
    ```

    3. ãƒãƒƒãƒæ¨è«–ã®å®Ÿè£…
    APIãƒ¢ãƒ‡ãƒ«ã¨ç•°ãªã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯**ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ã‹ã‚‰ãƒãƒƒãƒã§å‡¦ç†**ã™ã‚‹ã“ã¨ã§åŠ¹ç‡åŒ–ï¼š

    ```python
    def batch_inference(self, test_entries, num_gpus, gpu_memory_utilization, ...):
        # 1. ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰
        self.tokenizer = AutoTokenizer.from_pretrained(**load_kwargs)
        config = AutoConfig.from_pretrained(**load_kwargs)
        
        # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®è¨­å®š
        if hasattr(config, "max_position_embeddings"):
            self.max_context_length = config.max_position_embeddings
        
        # 3. ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè¡Œ
        # (å€‹åˆ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ä¸€åº¦ã«ã¾ã¨ã‚ã¦å‡¦ç†)
    ```

    4. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
    ```python
    @override
    def decode_ast(self, result, language="Python"):
        return default_decode_ast_prompting(result, language)

    @override
    def decode_execute(self, result):
        return default_decode_execute_prompting(result)
    ```

    5. ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¨å®š
    ```python
    # Chat Completions APIã§ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
    messages_text = " ".join([msg.get("content", "") for msg in message])
    input_token_count = len(self.tokenizer.tokenize(messages_text))
    ```

- å‡¦ç†ãƒ•ãƒ­ãƒ¼

    ```
    1. ãƒãƒƒãƒæ¨è«–é–‹å§‹
    â†“
    2. ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ­ãƒ¼ãƒ‰ (vLLMã‚µãƒ¼ãƒãƒ¼ãŒã™ã§ã«èµ·å‹•ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—)
    â†“
    3. vLLMã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šç¢ºç«‹
    â†“
    4. ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®å‰å‡¦ç†
    â†“
    5. Chat Completions APIçµŒç”±ã§ã‚¯ã‚¨ãƒª
    â†“
    6. å¿œç­”ã®è§£æãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰
    â†“
    7. çµæœã®ä¿å­˜
    ```

### 4: bfcl/model_handler/local_inferenceå†…ã®è¿½åŠ ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã‚’æ•™ãˆã¦

local_inferenceãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯**25å€‹ä»¥ä¸Šã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼**ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€base_oss_handler.pyã®**OSSHandler**ã‚’ç¶™æ‰¿ã—ã¦ã€å„ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®å‡¦ç†ã‚’æœ€å°é™ã®å®Ÿè£…ã§æä¾›ã—ã¦ã„ã¾ã™ã€‚

- Nejumi Leaderboardã®ãŸã‚ã«å‰Šé™¤ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰
    - **`_format_prompt`**: Chat Completions APIãŒvLLMã‚µãƒ¼ãƒãƒ¼å´ã§çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å‡¦ç†ã™ã‚‹ãŸã‚ä¸è¦

- ä¾ç„¶ã¨ã—ã¦å¿…è¦ãªãƒ¡ã‚½ãƒƒãƒ‰
    - **`decode_ast`/`decode_execute`**: å‡ºåŠ›ãƒ‘ãƒ¼ã‚¹ã¯ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãŸã‚å¿…è¦
    - **`_pre_query_processing_prompting`**: å‰å‡¦ç†ã¯ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãŸã‚å¿…è¦
    - **`_add_execution_results_prompting`**: å®Ÿè¡Œçµæœã®å‡¦ç†æ–¹æ³•ãŒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹

- ãƒ¢ãƒ‡ãƒ«åˆ¥ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å¯¾å¿œãŒå¿…è¦ãªç†ç”±ã¨å…·ä½“ä¾‹
    - ãƒ¢ãƒ‡ãƒ«åˆ¥ç‰¹å¾´ã¾ã¨ã‚
        | ãƒ¢ãƒ‡ãƒ« | å‡ºåŠ›ã®ç‰¹å¾´ | ä¸»ãªå‡¦ç† |
        |--------|------------|----------|
        | **Hammer** | æ¨™æº–JSON | æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ« |
        | **DeepSeek** | ```json\n...\n``` | ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å» |
        | **Llama 3.1** | <python_tag>...;... | ã‚¿ã‚°é™¤å»+ã‚»ãƒŸã‚³ãƒ­ãƒ³åˆ†å‰² |
        | **MiniCPM** | æ€è€ƒéç¨‹+ãƒ„ãƒ¼ãƒ«ã‚¿ã‚° | è¤‡é›‘ãªã‚¿ã‚°è§£æ |
        | **Phi** | ```json/python... | è¤‡æ•°ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¯¾å¿œ |
        | **GLM** | æ”¹è¡ŒåŒºåˆ‡ã‚Š | ç‰¹æ®Šãªæ”¹è¡Œå‡¦ç† |
        | **Granite** | <function_call>... | XMLãƒ©ã‚¤ã‚¯ã‚¿ã‚° |

    - å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã‚‹ç†ç”±
        1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®é•ã„
        - å„ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ãŸã‚

        2. ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é•ã„
        - ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¦å‰‡ãŒã‚ã‚‹ãŸã‚

        3. è¨­è¨ˆæ€æƒ³ã®é•ã„
        - å‡ºåŠ›ã®è©³ç´°ã•ã‚„æ§‹é€ ã«å¯¾ã™ã‚‹è€ƒãˆæ–¹ãŒç•°ãªã‚‹ãŸã‚

    1. ã‚·ãƒ³ãƒ—ãƒ«ãªã‚±ãƒ¼ã‚¹: hammer.py
        ```python
        class HammerHandler(OSSHandler):
            @override
            def decode_ast(self, result, language="Python"):
                # å˜ç´”ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— + ç›´æ¥JSONãƒ‘ãƒ¼ã‚¹
                result = result.replace("```", "")
                try:
                    result = json.loads(result)
                except:
                    result = []
                
                decoded_output = []
                for invoked_function in result:
                    name = invoked_function["name"]
                    params = invoked_function["arguments"]
                    decoded_output.append({name: params})
                return decoded_output
        ```

        æœŸå¾…ã•ã‚Œã‚‹æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
        ```json
        [{"name": "function_name", "arguments": {"param": "value"}}]
        ```

    2. ç‰¹æ®Šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œ: deepseek.py
        ```python
        class DeepseekHandler(OSSHandler):
            @override
            def decode_ast(self, result, language="Python"):
                result = result.strip()
                # ```json ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
                if result.startswith("```json"):
                    result = result[len("```json"):]
                if result.startswith("```python"):
                    result = result[len("```python"):]
                return super().decode_ast(result, language)
        ```

        DeepSeekã®å®Ÿéš›ã®å‡ºåŠ›ä¾‹:
        ```
            ```json
            {"name": "calculate", "arguments": {"x": 5, "y": 10}}
            ```
        ```

    3. è¤‡é›‘ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: llama_3_1.py
        ```python
        class Llama31Handler(OSSHandler):
            @override
            def decode_ast(self, result, language="Python"):
                # ã‚¿ã‚°é™¤å»ã€ã‚»ãƒŸã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚Šå¯¾å¿œ
                result = result.replace("<|python_tag|>", "").strip()
                calls = result.split(";")
                return [json.loads(call.strip()) for call in calls if call.strip()]
        ```

        Llama 3.1ã®å®Ÿéš›ã®å‡ºåŠ›ä¾‹:
        ```
        <|python_tag|>{"name": "calc", "arguments": {...}}; {"name": "func2", "arguments": {...}}
        ```

    4. è¶…è¤‡é›‘ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: minicpm_fc.py
        ```python
        def fc2dict(sequence: str, 
                tool_call_start="<|tool_call_start|>",
                tool_call_end="<|tool_call_end|>",
                thought_start="<|thought_start|>",
                thought_end="<|thought_end|>"):
            # æ€è€ƒéç¨‹ã¨ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚¿ã‚°ã‚’å«ã‚€è¤‡é›‘ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            if thought_end in sequence and thought_start in sequence:
                thought_string, sequence = sequence.rsplit(thought_end, 1)
                thought_string = thought_string.split(thought_start, 1)[1]
            
            if tool_call_start in sequence and tool_call_end in sequence:
                tool_call_string, content = sequence.rsplit(tool_call_end, 1)
                tool_call_string = tool_call_string.split(tool_call_start, 1)[1]
                # ASTè§£æã§é–¢æ•°å‘¼ã³å‡ºã—ã‚’æŠ½å‡º
                parsed = ast.parse(tool_call_string)
                # ...
        ```

        MiniCPMã®å®Ÿéš›ã®å‡ºåŠ›ä¾‹:
        ```
        <|thought_start|>
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¨ˆç®—ã‚’æ±‚ã‚ã¦ã„ã‚‹ã®ã§ã€calculateé–¢æ•°ã‚’ä½¿ã„ã¾ã™
        <|thought_end|>
        <|tool_call_start|>
            ```python
            calculate(x=5, y=10)
            ```
        <|tool_call_end|>
        è¨ˆç®—çµæœã‚’ãŠè¦‹ã›ã—ã¾ã™
        ```

    5. å®Ÿè¡Œçµæœã®å‡¦ç†æ–¹æ³•ã®é•ã„
        - æ¨™æº–çš„ãªå‡¦ç†ï¼ˆDeepSeekï¼‰
            ```python
            def _add_execution_results_prompting(self, inference_data, execution_results, model_response_data):
                # DeepSeekã¯toolãƒ­ãƒ¼ãƒ«ã‚’å—ã‘ä»˜ã‘ãªã„ãŸã‚ã€userãƒ­ãƒ¼ãƒ«ã‚’ä½¿ç”¨
                tool_message = {"role": "user", "content": []}
                for execution_result, decoded_model_response in zip(execution_results, model_response_data["model_responses_decoded"]):
                    tool_message["content"].append({
                        "role": "tool",
                        "name": decoded_model_response,
                        "content": execution_result,
                    })
                inference_data["message"].append(tool_message)
            ```

        - ç‰¹æ®Šãªãƒ­ãƒ¼ãƒ«ä½¿ç”¨ï¼ˆLlamaï¼‰
            ```python
            def _add_execution_results_prompting(self, inference_data, execution_results, model_response_data):
                for execution_result in execution_results:
                    # Llamaã¯ç‰¹æ®Šãª`ipython`ãƒ­ãƒ¼ãƒ«ã‚’ä½¿ç”¨
                    inference_data["message"].append({
                        "role": "ipython",
                        "content": execution_result,
                    })
            ```
