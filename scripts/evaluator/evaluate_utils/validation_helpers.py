"""
YAMLè¨­å®šã®ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½

reasoningæ©Ÿèƒ½ä½¿ç”¨æ™‚ã«å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒååˆ†ã«ç¢ºä¿ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
"""
import warnings
from typing import Dict, Any, Optional, Tuple
from omegaconf import DictConfig


def get_reasoning_tokens(cfg: DictConfig) -> Optional[int]:
    """è¨­å®šã‹ã‚‰reasoningç”¨ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—"""
    try:
        # generator.extra_body.reasoning.max_tokens ã‚’ç¢ºèª
        if hasattr(cfg, 'generator') and hasattr(cfg.generator, 'extra_body'):
            extra_body = cfg.generator.extra_body
            if hasattr(extra_body, 'reasoning') and hasattr(extra_body.reasoning, 'max_tokens'):
                return int(extra_body.reasoning.max_tokens)
    except (AttributeError, ValueError, TypeError):
        pass
    
    return None


def get_max_output_tokens(cfg: DictConfig, benchmark_name: str) -> Optional[int]:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ã®æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å–å¾—"""
    try:
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å›ºæœ‰ã®è¨­å®šã‚’ç¢ºèª
        benchmark_cfg = getattr(cfg, benchmark_name, None)
        if benchmark_cfg is not None:
            # å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
            patterns = [
                'max_tokens',
                'max_new_token', 
                'max_completion_tokens',
                'max_output_tokens'
            ]
            
            for pattern in patterns:
                if hasattr(benchmark_cfg, pattern):
                    value = getattr(benchmark_cfg, pattern)
                    if value is not None:
                        return int(value)
            
            # generator_config.max_tokensã‚‚ç¢ºèª
            if hasattr(benchmark_cfg, 'generator_config'):
                gen_cfg = benchmark_cfg.generator_config
                if hasattr(gen_cfg, 'max_tokens'):
                    return int(gen_cfg.max_tokens)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: generator.max_tokens
        if hasattr(cfg, 'generator') and hasattr(cfg.generator, 'max_tokens'):
            return int(cfg.generator.max_tokens)
            
    except (AttributeError, ValueError, TypeError):
        pass
    
    return None


def check_token_allocation(cfg: DictConfig, benchmark_name: str) -> Tuple[bool, str]:
    """
    ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€reasoningå¾Œã«å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒç¢ºä¿ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèª
    
    Returns:
        (is_valid, message): ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    reasoning_tokens = get_reasoning_tokens(cfg)
    max_output_tokens = get_max_output_tokens(cfg, benchmark_name)
    
    # æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ãŒå–å¾—ã§ããªã„å ´åˆã¯è­¦å‘Š
    if max_output_tokens is None:
        return False, f"âš ï¸  {benchmark_name}: æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    # reasoningæ©Ÿèƒ½ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„å ´åˆ
    if reasoning_tokens is None:
        # reasoningæœªä½¿ç”¨æ™‚ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ0ä»¥ä¸Šã§ã‚ã‚Œã°ååˆ†ï¼ˆæŠä¸€å•é¡Œãªã©1ãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚‚OKï¼‰
        if max_output_tokens > 0:
            return True, f"âœ“ {benchmark_name}: Reasoningæ©Ÿèƒ½æœªä½¿ç”¨ - ãƒˆãƒ¼ã‚¯ãƒ³æ•°OK ({max_output_tokens})"
        else:
            return False, f"âŒ {benchmark_name}: æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ãŒ0ä»¥ä¸‹ã§ã™ ({max_output_tokens})"
    
    # reasoningæ©Ÿèƒ½ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆ
    # å®Ÿéš›ã®å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ = æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ - reasoningç”¨ãƒˆãƒ¼ã‚¯ãƒ³
    available_output_tokens = max_output_tokens - reasoning_tokens
    
    if available_output_tokens <= 0:
        return False, (
            f"âŒ {benchmark_name}: å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸è¶³ã—ã¦ã„ã¾ã™\n"
            f"   æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {max_output_tokens}\n"
            f"   Reasoningç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {reasoning_tokens}\n"
            f"   å‡ºåŠ›ç”¨æ®‹ã‚Šãƒˆãƒ¼ã‚¯ãƒ³: {available_output_tokens} (â‰¤ 0)"
        )
    elif available_output_tokens < 512:  # reasoningä½¿ç”¨æ™‚ã¯512ä»¥ä¸Šæ¨å¥¨
        return False, (
            f"âš ï¸  {benchmark_name}: Reasoningä½¿ç”¨æ™‚ã®å‡ºåŠ›ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒå°‘ãªã„ã§ã™\n"
            f"   æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {max_output_tokens}\n"
            f"   Reasoningç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {reasoning_tokens}\n"
            f"   å‡ºåŠ›ç”¨æ®‹ã‚Šãƒˆãƒ¼ã‚¯ãƒ³: {available_output_tokens} (< 512æ¨å¥¨)"
        )
    else:
        return True, (
            f"âœ“ {benchmark_name}: ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†OK\n"
            f"   æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: {max_output_tokens}\n"
            f"   Reasoningç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {reasoning_tokens}\n"
            f"   å‡ºåŠ›ç”¨æ®‹ã‚Šãƒˆãƒ¼ã‚¯ãƒ³: {available_output_tokens}"
        )


def pre_evaluation_check(cfg: DictConfig, benchmark_name: str) -> bool:
    """
    è©•ä¾¡å®Ÿè¡Œå‰ã®ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ãƒã‚§ãƒƒã‚¯
    
    Args:
        cfg: OmegaConfè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        benchmark_name: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å (mtbench, bfcl, swebenchç­‰)
    
    Returns:
        bool: è©•ä¾¡ã‚’ç¶šè¡Œã—ã¦è‰¯ã„ã‹ã©ã†ã‹
    """
    is_valid, message = check_token_allocation(cfg, benchmark_name)
    
    print("=" * 60)
    print("ğŸ” ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)
    print(message)
    print("=" * 60)
    
    if not is_valid:
        print("\nğŸ’¡ æ¨å¥¨å¯¾å¿œ:")
        reasoning_tokens = get_reasoning_tokens(cfg)
        if reasoning_tokens:
            print(f"   1. reasoning.max_tokensã‚’{reasoning_tokens}ã‹ã‚‰å‰Šæ¸›")
            print(f"   2. å„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®max_tokensã‚’å¢—åŠ ")
            print(f"   3. ä¸€æ™‚çš„ã«reasoningæ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–")
        print("\nâš ï¸  ã“ã®ã¾ã¾è©•ä¾¡ã‚’ç¶šè¡Œã™ã‚‹ã¨ã€ç©ºç™½å›ç­”ã«ã‚ˆã‚Šä¸å½“ã«ä½ã„ã‚¹ã‚³ã‚¢ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        # å¼·åˆ¶çµ‚äº†ã¯ã›ãšã€è­¦å‘Šã®ã¿è¡¨ç¤º
        response = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        return response in ['y', 'yes']
    
    return True


def validate_all_benchmarks(cfg: DictConfig) -> Dict[str, Tuple[bool, str]]:
    """
    ã™ã¹ã¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
    
    Returns:
        Dict[benchmark_name, (is_valid, message)]
    """
    # ä¸»è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸€è¦§
    benchmarks = [
        'mtbench', 'bfcl', 'swebench', 'jbbq', 'toxicity', 
        'jtruthfulqa', 'hle', 'hallulens', 'arc_agi', 'm_ifeval', 'jaster'
    ]
    
    results = {}
    for benchmark in benchmarks:
        # å®Ÿéš›ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã¿ãƒã‚§ãƒƒã‚¯
        if hasattr(cfg, benchmark):
            results[benchmark] = check_token_allocation(cfg, benchmark)
    
    return results


if __name__ == "__main__":
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
    from omegaconf import OmegaConf
    import sys
    
    if len(sys.argv) > 1:
        config_path = sys.argv[1]
        try:
            cfg = OmegaConf.load(config_path)
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {config_path}")
            results = validate_all_benchmarks(cfg)
            
            print("\n" + "=" * 60)
            print("ğŸ“Š å…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ†ãƒã‚§ãƒƒã‚¯çµæœ")
            print("=" * 60)
            
            for benchmark, (is_valid, message) in results.items():
                print(f"\n{message}")
                
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("ä½¿ç”¨æ–¹æ³•: python validation_helpers.py <config_file.yaml>")